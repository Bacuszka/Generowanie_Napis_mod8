import streamlit as st
import hashlib
import tempfile
import os
import srt
from pydub import AudioSegment
from io import BytesIO
from dotenv import load_dotenv
import openai
from datetime import timedelta
import imageio_ffmpeg as ffmpeg  # Dodaj import na poczÄ…tku


# ZaÅ‚aduj zmienne Å›rodowiskowe
load_dotenv()

# Sprawdzenie lokalizacji ffprobe (moÅ¼esz wyÅ›wietliÄ‡ to w konsoli, jeÅ›li potrzebujesz)
ffprobe_path = ffmpeg.get_ffmpeg_exe()
print("FFprobe path:", ffprobe_path)  # To wyÅ›wietli Å›cieÅ¼kÄ™ do ffprobe w konsoli

st.markdown(
    """
    <style>
    video {
        max-width: 700px;
        width: 800px;
        height: 600px;
    }
    </style>
    """,
    unsafe_allow_html=True
)

def get_md5(file_data):
    hasher = hashlib.md5()
    hasher.update(file_data)
    return hasher.hexdigest()

def process_video(file):
    file_data = file.read()
    file_md5 = get_md5(file_data)

    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as temp_file:
        temp_file.write(file_data)
        temp_filename = temp_file.name

    st.subheader("PrzesÅ‚ane wideo: ğŸ¥")
    st.video(temp_filename, format="video/mp4", start_time=0)
    
    st.session_state["video_path"] = temp_filename
    st.session_state["video_filename"] = file.name.rsplit(".", 1)[0]

    if st.button("WyodrÄ™bnij audio z wideo ğŸ§"):
        extract_audio()

def extract_audio():
    video_path = st.session_state.get("video_path", None)
    if not video_path:
        st.error("Najpierw zaÅ‚aduj plik wideo.")
        return

    try:
        audio = AudioSegment.from_file(video_path)
        audio_mp3 = BytesIO()
        audio.export(audio_mp3, format="mp3")
        audio_mp3.seek(0)

        st.subheader("WyodrÄ™bnione audio: ğŸµ")
        st.markdown("<h4 style='font-size: 20px;'>Po transkrypcji drugi odtwarzacz zniknie. âŒ</h4>", unsafe_allow_html=True)
        st.audio(audio_mp3, format="audio/mp3")

        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as temp_audio_file:
            temp_audio_file.write(audio_mp3.read())
            temp_audio_filename = temp_audio_file.name

        st.session_state["audio_path"] = temp_audio_filename
        st.success("Audio zostaÅ‚o wyodrÄ™bnione!")
    except Exception as e:
        st.error(f"Nie udaÅ‚o siÄ™ wyodrÄ™bniÄ‡ dÅºwiÄ™ku. BÅ‚Ä…d: {str(e)}")

def transcribe_audio():
    audio_path = st.session_state.get("audio_path", None)
    if not audio_path:
        st.error("Najpierw wyodrÄ™bnij audio.")
        return
    
    try:
        client = openai.DeepAI(api_key=st.session_state.openai_api_key)
        with open(audio_path, "rb") as f:
            with st.spinner("Transkrypcja w toku..."):
                transcript = client.audio.transcriptions.create(
                    file=f,
                    model="whisper-1",
                    response_format="verbose_json"
                )

        segments = transcript.segments
        transcript_text = "\n".join([segment.text for segment in segments])
        st.session_state["transcript_text"] = transcript_text
        st.session_state["segments"] = segments
        st.success("Transkrypcja zakoÅ„czona! MoÅ¼esz teraz edytowaÄ‡ tekst.")

        # Generowanie podsumowania zaraz po transkrypcji
        generate_summary()
    except Exception as e:
        st.error(f"Nie udaÅ‚o siÄ™ uzyskaÄ‡ transkrypcji. BÅ‚Ä…d: {str(e)}")

def generate_srt():
    if "segments" not in st.session_state:
        st.error("Brak transkrypcji do zapisania.")
        return

    transcript_text = st.session_state.get("transcript_text", "")
    edited_segments = transcript_text.split("\n")

    subtitles = []
    for i, (segment, text) in enumerate(zip(st.session_state["segments"], edited_segments)):
        start_time = timedelta(seconds=segment.start)
        end_time = timedelta(seconds=segment.end)
        subtitles.append(srt.Subtitle(index=i+1, start=start_time, end=end_time, content=text))
    
    srt_data = srt.compose(subtitles)
    st.session_state["srt_text"] = srt_data
    st.success("Napisy w formacie .srt zostaÅ‚y wygenerowane!")

def translate_srt():
    if "srt_text" not in st.session_state:
        st.error("Najpierw wygeneruj plik SRT.")
        return
    
    client = openai.DeepAI(api_key=st.session_state.openai_api_key)
    
    with st.spinner("TÅ‚umaczenie na jÄ™zyk polski..."):
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[{"role": "system", "content": "PrzetÅ‚umacz nastÄ™pujÄ…ce napisy SRT na jÄ™zyk polski, zachowujÄ…c formatowanie."},
                      {"role": "user", "content": st.session_state["srt_text"]}]
        )
    
    # Zapisz przetÅ‚umaczone napisy w session_state
    st.session_state["srt_text_translated"] = response.choices[0].message.content
    st.success("Napisy przetÅ‚umaczone na jÄ™zyk polski!")

def generate_summary():
    transcript_text = st.session_state.get("transcript_text", "")
    if not transcript_text:
        st.error("Brak transkrypcji do podsumowania.")
        return
    
    try:
        client = openai.DeepAI(api_key=st.session_state.openai_api_key)
        with st.spinner("Generowanie podsumowania..."):
            response = client.chat.completions.create(
                model="gpt-4-turbo",
                messages=[{"role": "system", "content": "Na podstawie poniÅ¼szej transkrypcji, stwÃ³rz krÃ³tki opis filmu (do 300 znakÃ³w)."},
                          {"role": "user", "content": transcript_text}]
            )
        
        summary = response.choices[0].message.content.strip()
        st.session_state["summary"] = summary[:300]  # Ogranicz do 300 znakÃ³w
        st.success("Podsumowanie zostaÅ‚o wygenerowane!")
    except Exception as e:
        st.error(f"Nie udaÅ‚o siÄ™ wygenerowaÄ‡ podsumowania. BÅ‚Ä…d: {str(e)}")

api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    api_key = st.text_input("Podaj swÃ³j klucz API DeepAI", type="password")
    if api_key:
        os.environ["OPENAI_API_KEY"] = api_key
        st.session_state.openai_api_key = api_key
        st.success("Klucz API DeepAI zostaÅ‚ ustawiony.")
else:
    st.session_state.openai_api_key = api_key
    st.success("Klucz API DeepAI zaÅ‚adowany z pliku .env.")

# Inicjalizacja klucza session_state "srt_text_translated" jeÅ›li nie istnieje
if "srt_text_translated" not in st.session_state:
    st.session_state["srt_text_translated"] = ""

st.title("Generowanie napisÃ³w do filmu ğŸ§¾")
st.subheader("""
Aplikacja do transkrypcji wideo

Opis
Aplikacja umoÅ¼liwia uÅ¼ytkownikowi przesÅ‚anie pliku wideo, wyodrÄ™bnienie z niego dÅºwiÄ™ku,
transkrypcjÄ™ mowy na tekst, generowanie napisÃ³w SRT oraz opcjonalne ich tÅ‚umaczenie na jÄ™zyk polski.
Dodatkowo generuje podsumowanie filmu na podstawie transkrypcji.

Funkcje:

1. WyodrÄ™bnienie audio z wideo
2. Transkrypcja audio na tekst
3. Generowanie napisÃ³w .srt
4. TÅ‚umaczenie tekstu na jÄ™zyk polski
5. Generowanie podsumowania

Uwagi:
* UÅ¼ytkownik powinien mieÄ‡ wÅ‚asny klucz API DeepAI.
* UÅ¼ytkownik przesyÅ‚a plik wideo w formatach (mp4, mov, avi).

""")
uploaded_file = st.file_uploader("Wybierz plik wideo ğŸ¬", type=["mp4", "mov", "avi"])
if uploaded_file:
    process_video(uploaded_file)

# Pokazanie audio playera, jeÅ¼eli istnieje
if "audio_path" in st.session_state:
    audio_file = st.session_state.get("audio_path", None)
    if audio_file:
        st.audio(audio_file, format="audio/mp3")

if "audio_path" in st.session_state:
    if st.button("Transkrybuj z Whisper-1 [Open AI] ğŸ¤–"):
        transcribe_audio()

if "transcript_text" in st.session_state:
    # Ustawienie text_area na edytowalny tekst do pliku SRT
    transcript_text = st.text_area("Edytuj transkrypcjÄ™: âœï¸", st.session_state["transcript_text"], height=300)
    st.session_state["transcript_text"] = transcript_text
    if st.button("Wygeneruj napisy .srt ğŸ§¾"):
        generate_srt()

    if st.button("PrzetÅ‚umacz na polski ğŸ¥ŸğŸ‡µğŸ‡±"):
        translate_srt()
        # Zaktualizuj text_area na przetÅ‚umaczony tekst
        st.session_state["transcript_text"] = st.session_state["srt_text_translated"]
        transcript_text = st.session_state["transcript_text"]
        st.text_area("Edytuj transkrypcjÄ™:", transcript_text, height=300)

    # Opcja schowania/wyÅ›wietlenia podsumowania
    if "summary" in st.session_state:
        with st.expander("Podsumowanie filmu (kliknij, aby rozwinÄ…Ä‡) ğŸ‘â€ğŸ—¨"):
            st.write(st.session_state["summary"])

# WyÅ›wietl przycisk "Pobierz napisy .srt" tylko wtedy, gdy napisy sÄ… dostÄ™pne
if "srt_text" in st.session_state:
    video_filename = st.session_state.get("video_filename", "napisy")  # Pobierz nazwÄ™ pliku z session_state
    srt_filename = f"{video_filename}.srt"
    st.download_button("Pobierz napisy (.srt) ğŸ’¾", st.session_state["srt_text"], file_name=srt_filename, mime="text/plain")

# WyÅ›wietl przycisk "Pobierz przetÅ‚umaczone napisy" tylko po tÅ‚umaczeniu
if "srt_text_translated" in st.session_state and st.session_state["srt_text_translated"]:
    video_filename = st.session_state.get("video_filename", "napisy")  # Pobierz nazwÄ™ pliku z session_state
    translated_srt_filename = f"{video_filename}_PL.srt"
    st.download_button("Pobierz przetÅ‚umaczone napisy (.srt)ğŸ§‘â€ğŸ¤", st.session_state["srt_text_translated"], file_name=translated_srt_filename, mime="text/plain")